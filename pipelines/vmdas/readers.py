import warnings
from pathlib import Path
from typing import Dict, Union
from pydantic import BaseModel, Extra
import numpy as np
import pandas as pd
import xarray as xr
from datetime import datetime
import mhkit.dolfyn as dolfyn
from mhkit.dolfyn.adp import api
from tsdat import DataReader
import pynmea2


class VmdasADCPReader(DataReader):
    class Parameters(BaseModel, extra=Extra.forbid):
        depth_offset: float = 1
        magnetic_declination: float = 0
        heading_misalignment: float = 45

    parameters: Parameters = Parameters()

    def read(self, input_key: str) -> Union[xr.Dataset, Dict[str, xr.Dataset]]:
        """-------------------------------------------------------------------
        Reads binary files generated by Teledyne Vmdas software. These
        files contain limited GPS data, but the software stores the raw GPS
        data in auxillary files labeled .N1R, .N2R, and/or .N3R.
        This reader will also read the raw GPS data stored in these files.

        Args:
            filename (str): The path to the ADCP file to read in.

        Returns:
            xr.Dataset: An xr.Dataset object
        -------------------------------------------------------------------"""

        ds = dolfyn.read(input_key, search_vmdas=True)

        # Set depth below water surface
        api.clean.set_range_offset(ds, self.parameters.depth_offset)
        if "dist_bt" in ds:
            ds["depth"] = ds.attrs["range_offset"] + ds["dist_bt"].mean("beam")
        else:
            depth = (ds["amp"] > 200) * ds["range"]
            depth = depth.where(depth != 0).mean("range").mean("beam")
            ds["depth"].values = depth + ds.cell_size

        # Reset heading misalignment
        ds.attrs["heading_misalign_deg"] = self.parameters.heading_misalignment

        # Rotate to Earth coordinates (necessary for pipeline hook)
        dolfyn.set_declination(ds, self.parameters.magnetic_declination)
        dolfyn.rotate2(ds, "earth")

        # Set time to UTC time (corrects for unsync'd clock time)
        utc_time = ds["time"] - np.timedelta64(
            int(ds["clock_offset_UTC_gps"].mean() * 1000), "ms"
        )
        ds = ds.assign_coords({"time": utc_time})

        ## Read in NMEA files
        dc_nmea = self.read_nmea(Path(input_key).with_suffix(".N1R"))
        dc_vtg = self.read_nmea(Path(input_key).with_suffix(".N2R"))
        dc_hdt = self.read_nmea(Path(input_key).with_suffix(".N3R"))
        dc_nmea["dir_over_grnd_gps"] = dc_vtg["dir_over_grnd_gps"]
        dc_nmea["speed_over_grnd_gps"] = dc_vtg["speed_over_grnd_gps"]  # knots
        dc_nmea["heading_gps"] = dc_hdt["heading_gps"]

        # Combine datafiles. If the ADCP clock is not in UTC, there can be
        # discrepancies in the timestamps since the date is not recorded in the GPS
        # sentences. Unfortunately there is not an option to save the RMC sentence
        # which includes a date stamp.
        start_day = dolfyn.time.dt642date(ds["time"][0].astype("datetime64[D]"))[0]
        for ky in dc_nmea:
            if "time" in ky:
                dates = [datetime.combine(start_day, dt) for dt in dc_nmea[ky]]
                dc_nmea[ky] = dolfyn.time.date2dt64(dates)
                # If the time jumps by nearly 24 hours at any given instance, we've skipped a day
                epoch = dolfyn.time.dt642epoch(dc_nmea[ky])
                time_diff = np.diff(epoch)
                if any(np.array(list(set(time_diff))) < -(23.9 * 3600)):
                    idx = np.where(time_diff == time_diff.min())[0]
                    epoch[int(idx) + 1 :] += 24 * 3600
                    dc_nmea[ky] = dolfyn.time.epoch2dt64(epoch)
            dc_nmea[ky] = {"dims": ("time_gps"), "data": dc_nmea[ky]}

        ds_nmea = xr.Dataset.from_dict(dc_nmea)
        ds = ds.merge(ds_nmea, ds, "override")

        return ds

    def read_nmea(self, input_name):
        """Reads NMEA files stored with the VMDAS files."""

        def get(item, key):
            out = getattr(item, key)
            if out is None:
                out = np.nan
            return out

        df = pd.read_csv(input_name, header=None, sep="\\")
        d = []
        for row in df[0]:
            try:
                d.append(pynmea2.parse(row))
            except:
                pass

        new_dict: dict = {
            "time_gps": [],
            "latitude_gps": [],
            "longitude_gps": [],
            "fix_gps": [],
            "n_sat_gps": [],
            "elevation_gps": [],
            "hdop_gps": [],
            "dir_over_grnd_gps": [],
            "speed_over_grnd_gps": [],
            "heading_gps": [],
        }

        for t in d:
            try:  # skip strange sentences
                t.sentence_type
            except:
                continue

            if "GGA" in t.sentence_type:
                new_dict["time_gps"].append(get(t, "timestamp"))
                new_dict["latitude_gps"].append(get(t, "latitude"))
                new_dict["longitude_gps"].append(get(t, "longitude"))
                new_dict["fix_gps"].append(int(get(t, "gps_qual")))
                new_dict["n_sat_gps"].append(int(get(t, "num_sats")))
                new_dict["elevation_gps"].append(float(get(t, "altitude")))
                new_dict["hdop_gps"].append(float(get(t, "horizontal_dil")))

            elif "VTG" in t.sentence_type:
                new_dict["dir_over_grnd_gps"].append(float(get(t, "true_track")))
                new_dict["speed_over_grnd_gps"].append(
                    float(get(t, "spd_over_grnd_kts"))
                )

            elif "HDT" in t.sentence_type:
                new_dict["heading_gps"].append(float(get(t, "heading")))

        return new_dict
